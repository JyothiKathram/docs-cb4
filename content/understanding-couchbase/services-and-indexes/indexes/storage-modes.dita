<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_frt_5tr_zz">
  
  <title>
    Index Storage Settings
  </title>
  
  <shortdesc>
    A Secondary Index can be saved in either of two ways: <i>standard</i>
    or <i>memory-optmized</i>.    
  </shortdesc>
  
  <body>
    <section id="memopt-gsi2">
      
      <title>
        Memory-Optimized Index Storage
      </title>
      
      <p>
        Memory-optimized index-storage allows high-speed maintenance and scanning; since the index is
        kept fully in memory at all times. A snapshot of the index is maintained
        on disk, to permit rapid recovery if node-failures are experienced. Memory-optimized index-storage
        may be considered the better option, on nodes where the Index Service memory quota is sufficient
        for the number and complexity of resident indexes, and the intensity with which they are
        updated and scanned.
      </p>
      
      <p>
        However, memory-optimized index-storage may be problematic on nodes where memory is
        constrained:
        whenever 
        the Index Service memory-quota is exceeded, indexes on the node become unable to
        process changes, and an error-notification is provided. Though the indexes remain in
        <codeph>ONLINE</codeph> state, traffic is routed away from the node. In such cases,
        memory needs to be freed.
      </p>
      
      <p>
        In cases where an Index-Service node needs to be restarted, its resident memory-optimized indexes 
        are rebuilt from the snapshot retained on disk. 
        These indexes remain in the <codeph>BUILDING</codeph> state 
        until all information has been read into memory: then, final updates occur with the indexes in ONLINE state.
        From this point, queries with <codeph>consistency=request_plus</codeph> or
        <codeph>consistency=at_plus</codeph> fail, if the timestamp specified exceeds the last
        timestamp processed by the specific index on the node. However, queries with
        <codeph>consistency=unbounded</codeph> execute normally.
      </p>
      
      <p>
        The following measures may be considered, in order to recover from an out-of-memory situation: 
      </p>
      
      <p>
      </p>
        
        <ul id="ul_aps_f5g_sw2">
          
          <li>
            Increase the index-memory quota, to give indexes additional memory
            for request-processing.
            
            <p>
            </p>
          </li>
          
          <li>
            Remove less important indexes from the node, to free up memory. 
            
            <p>
            </p>
          </li>
          
          <li>
            Remove buckets with indexes: removing a bucket automatically removes all the dependent
            indexes, and has the same effect as removing all indexes on a bucket.
            
            <p>
            </p>
          </li>
          
          <li>
            Flush buckets with indexes: flushing a bucket deletes all data in a bucket; and even if
            there are pending updates that are not yet processed, flushing causes all indexes
            to drop their data. 
            
            <p>
              Note that attempting to delete bucket-data <i>selectively</i> during an out-of-memory condition does
              not succeed in decreasing memory-usage: such requested deletions, given the absence of memory,
              cannot be processed.
            </p>
              
            <p>
            </p>
          </li>
          
        </ul>
        
    </section>
    
    <section id="std-gsi2">
      
      <title>
        Standard Index Storage
      </title>
      
      <p>
        <i>Standard</i> is the default storage-setting for Secondary Indexes: the indexes are
        saved on disk; in a disk-optimized format that uses both memory and disk for index-maintenance
        and scanning.
      </p>
      
      
      <p>
        The performance of standard index storage
        depends on overall I/O performance. Each index saved with the <i>standard</i> option
        has two write modes: 
      </p>
        
        <ul>
          <li>
            <b>Append-only Write Mode</b>: Similar to disk-writes
            implemented in the data service. All changes are written to the
            end of the index-file, invalidating
            existing pages within the index file, and requiring frequent, full compaction.
            
            <p>
            </p>
          </li>
          
          <li>
            <b>Circular Write Mode</b>: Writes changes to the end of the index-file, until
            the relative index fragmentation (<codeph>stale
            data size</codeph> / <codeph>total file size</codeph>) exceeds 65%. <i>Block reuse</i> is
            then triggered: which means that new data is written into stale blocks where possible,
            rather than to the end of the file, optimizing I/O throughput.
            Full compaction is run once a day on each of the days specified as part of the
            <i>circular mode time interval setting</i>: note, however, that the index fragmentation
            data size will likely not decrease.
            
            <p>
            </p>
            
          </li>
          
        </ul>
      
       <p>
        By default, Couchbase Server uses Circular Write Mode for standard index storage. Append-only
        Write Mode is provided for backward compatibility with previous versions.
      </p>
      
      <p>
        When assigning indexes to nodes, note the disk I/O bandwidth on the node;
        as well as figures for CPU, memory, and other resources.
      </p>
      
    </section>
    

    <section>
      
      <title>
        Changing the Index Storage Setting
      </title>
      
      <p>
        The <b>Index Storage Setting</b>
        is a cluster-level setting, established at cluster-initialization for
        all indexes on the cluster, across all buckets. The setting
        cannot be changed dynamically. To change from one option to the other following
        cluster-initialization, all nodes running the Index Service must be removed. If
        the cluster is single-node, this means uninstalling and reinstalling Couchbase
        Server. When the cluster features multiple nodes, only a subset of which contain
        the Index Service, the 
        procedure is as follows:
      </p>
      
      <p>
        
      </p>
        
        <ol>
          <li>
            Identify the nodes running the Index Service. 
            
            <p>
            </p>
          </li>
          
          <li>
            Remove each of the nodes running the Index Service.
            Note that as Index-Service node are removed, so are the indexes they contain; and in consequence,
            any ongoing queries fail. 
            
            
            <p>
            </p>
          </li>
          
          <li>
            Perform a rebalance.
            
            <p>
            </p>
          </li>
          
          <li>
            Change the Index Storage Settings for the
            cluster.
            
            <p>
            </p>
          </li>
          
          <li>
            Add new Index-Service, nodes and confirm the revised storage mode. 
            
            <p>
              
            </p>
          </li>
          
        </ol>

      
    </section>
  </body>
</topic>
